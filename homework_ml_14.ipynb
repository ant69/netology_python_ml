{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5cde8c3e",
   "metadata": {},
   "source": [
    "# Задание\n",
    "### Преподаватель: \n",
    "Олег Булыгин, Даниил Корбут, Наталья Баданина\n",
    "\n",
    "### Цель:\n",
    "Применить на практике алгоритмы по автоматической оптимизации параметров моделей машинного обучения.\n",
    "\n",
    "### Описание задания:\n",
    "В домашнем задании нужно решить задачу классификации наличия болезни сердца у пациентов наиболее эффективно. Данные для обучения моделей необходимо загрузить самостоятельно с [сайта](https://www.kaggle.com/fedesoriano/heart-failure-prediction). Целевая переменная – наличие болезни сердца (HeartDisease). Она принимает значения 0 или 1 в зависимости от отсутствия или наличия болезни соответственно. Подробное описание признаков можно прочесть в описании датасета на сайте. Для выполнения работы не обязательно вникать в медицинские показатели.\n",
    "\n",
    "### Этапы работы:\n",
    "\n",
    "1. Получите данные и загрузите их в рабочую среду. (Jupyter Notebook или другую)\n",
    "\n",
    "2. Подготовьте датасет к обучению моделей:  \n",
    "a) Категориальные переменные переведите в цифровые значения. Можно использовать [pd.get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html), [preprocessing.LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html). Старайтесь не использовать для этой задачи циклы.\n",
    "\n",
    "3. Разделите выборку на обучающее и тестовое подмножество. 80% данных оставить на обучающее множество, 20% на тестовое.\n",
    "\n",
    "4. Обучите модель логистической регрессии с параметрами по умолчанию.\n",
    "\n",
    "5. Подсчитайте основные метрики модели. Используйте следующие метрики и функцию:\n",
    "<code>    cross_validate(…, cv=10, scoring=[‘accuracy’,‘recall’,‘precision’,‘f1’])</code>\n",
    "\n",
    "6. Оптимизируйте 3-4 параметра модели:  \n",
    "a) Используйте GridSearchCV.  \n",
    "b) Используйте RandomizedSearchCV.  \n",
    "c) *Добавьте в п. 6b 2-5 моделей классификации и вариации их параметров.  \n",
    "d) Повторите п. 5 после каждого итогового изменения параметров.  \n",
    "\n",
    "7. Сформулируйте выводы по проделанной работе:  \n",
    "a) Сравните метрики построенных моделей.  \n",
    "b) *Сравните с полученными результатами в домашнем задании по теме «Ансамблирование».  \n",
    "\n",
    "### Для получения зачета по этому домашнему заданию минимально необходимо:\n",
    "- обучить одну модель классификации;\n",
    "- оптимизировать параметры, используя метод из п. 6a;\n",
    "- вывести значения метрик.\n",
    "\n",
    "### Результат:\n",
    "- Получены знания по оптимизации параметров.\n",
    "\n",
    "### Форма выполнения:\n",
    "- ссылка на Jupyter Notebook, загруженный на GitHub;\n",
    "- ссылка на Google Colab;\n",
    "- файл с расширением .ipynb.\n",
    "\n",
    "### Инструменты:\n",
    "- Jupyter Notebook/Google Colab;\n",
    "- GitHub;\n",
    "- сайт с данными для обучения моделей.\n",
    "\n",
    "### Срок выполнения: \n",
    "дедлайн приема решений на проверку\n",
    "\n",
    "### *Рекомендации к выполнению:\n",
    "- Текст оформляйте в отдельной ячейке Jupyter Notebook/Google Colab в формате markdown.\n",
    "- У графиков должен быть заголовок, подписи осей, легенда (опционально). Делайте графики бОльшего размера, чем стандартный вывод, чтобы увеличить читабельность.\n",
    "- Убедитесь, что по ссылкам есть доступ на чтение/просмотр.\n",
    "- Убедитесь, что все ячейки в работе выполнены и можно увидеть их вывод без повторного запуска."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d7c0d21",
   "metadata": {},
   "source": [
    "### 1. Получите данные и загрузите их в рабочую среду. (Jupyter Notebook или другую)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e134325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd # Для работы с данными\n",
    "import scipy.stats # При работе со статистикой\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt  # Библиотека для визуализации результатов\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b9f1316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 918 entries, 0 to 917\n",
      "Data columns (total 12 columns):\n",
      " #   Column          Non-Null Count  Dtype  \n",
      "---  ------          --------------  -----  \n",
      " 0   Age             918 non-null    int64  \n",
      " 1   Sex             918 non-null    object \n",
      " 2   ChestPainType   918 non-null    object \n",
      " 3   RestingBP       918 non-null    int64  \n",
      " 4   Cholesterol     918 non-null    int64  \n",
      " 5   FastingBS       918 non-null    int64  \n",
      " 6   RestingECG      918 non-null    object \n",
      " 7   MaxHR           918 non-null    int64  \n",
      " 8   ExerciseAngina  918 non-null    object \n",
      " 9   Oldpeak         918 non-null    float64\n",
      " 10  ST_Slope        918 non-null    object \n",
      " 11  HeartDisease    918 non-null    int64  \n",
      "dtypes: float64(1), int64(6), object(5)\n",
      "memory usage: 86.2+ KB\n",
      "None\n",
      "              Age   RestingBP  Cholesterol   FastingBS       MaxHR  \\\n",
      "count  918.000000  918.000000   918.000000  918.000000  918.000000   \n",
      "mean    53.510893  132.396514   198.799564    0.233115  136.809368   \n",
      "std      9.432617   18.514154   109.384145    0.423046   25.460334   \n",
      "min     28.000000    0.000000     0.000000    0.000000   60.000000   \n",
      "25%     47.000000  120.000000   173.250000    0.000000  120.000000   \n",
      "50%     54.000000  130.000000   223.000000    0.000000  138.000000   \n",
      "75%     60.000000  140.000000   267.000000    0.000000  156.000000   \n",
      "max     77.000000  200.000000   603.000000    1.000000  202.000000   \n",
      "\n",
      "          Oldpeak  HeartDisease  \n",
      "count  918.000000    918.000000  \n",
      "mean     0.887364      0.553377  \n",
      "std      1.066570      0.497414  \n",
      "min     -2.600000      0.000000  \n",
      "25%      0.000000      0.000000  \n",
      "50%      0.600000      1.000000  \n",
      "75%      1.500000      1.000000  \n",
      "max      6.200000      1.000000  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ChestPainType</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>RestingECG</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>ExerciseAngina</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ST_Slope</th>\n",
       "      <th>HeartDisease</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>172</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>F</td>\n",
       "      <td>NAP</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>156</td>\n",
       "      <td>N</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>M</td>\n",
       "      <td>ATA</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>ST</td>\n",
       "      <td>98</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>F</td>\n",
       "      <td>ASY</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>108</td>\n",
       "      <td>Y</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Flat</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>M</td>\n",
       "      <td>NAP</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>Normal</td>\n",
       "      <td>122</td>\n",
       "      <td>N</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Up</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age Sex ChestPainType  RestingBP  Cholesterol  FastingBS RestingECG  MaxHR  \\\n",
       "0   40   M           ATA        140          289          0     Normal    172   \n",
       "1   49   F           NAP        160          180          0     Normal    156   \n",
       "2   37   M           ATA        130          283          0         ST     98   \n",
       "3   48   F           ASY        138          214          0     Normal    108   \n",
       "4   54   M           NAP        150          195          0     Normal    122   \n",
       "\n",
       "  ExerciseAngina  Oldpeak ST_Slope  HeartDisease  \n",
       "0              N      0.0       Up             0  \n",
       "1              N      1.0     Flat             1  \n",
       "2              N      0.0       Up             0  \n",
       "3              Y      1.5     Flat             1  \n",
       "4              N      0.0       Up             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('heart.csv')\n",
    "print(data.info())\n",
    "print(data.describe())\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc57482",
   "metadata": {},
   "source": [
    "### 2. Подготовьте датасет к обучению моделей.  \n",
    "a) Категориальные переменные переведите в цифровые значения. Можно использовать [pd.get_dummies](https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html), [preprocessing.LabelEncoder](https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.LabelEncoder.html). Старайтесь не использовать для этой задачи циклы. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40352322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ChestPainType_ASY</th>\n",
       "      <th>ChestPainType_ATA</th>\n",
       "      <th>ChestPainType_NAP</th>\n",
       "      <th>ChestPainType_TA</th>\n",
       "      <th>RestingECG_LVH</th>\n",
       "      <th>RestingECG_Normal</th>\n",
       "      <th>RestingECG_ST</th>\n",
       "      <th>ST_Slope_Down</th>\n",
       "      <th>ST_Slope_Flat</th>\n",
       "      <th>ST_Slope_Up</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "      <td>918.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.540305</td>\n",
       "      <td>0.188453</td>\n",
       "      <td>0.221133</td>\n",
       "      <td>0.050109</td>\n",
       "      <td>0.204793</td>\n",
       "      <td>0.601307</td>\n",
       "      <td>0.193900</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0.501089</td>\n",
       "      <td>0.430283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.498645</td>\n",
       "      <td>0.391287</td>\n",
       "      <td>0.415236</td>\n",
       "      <td>0.218289</td>\n",
       "      <td>0.403770</td>\n",
       "      <td>0.489896</td>\n",
       "      <td>0.395567</td>\n",
       "      <td>0.252957</td>\n",
       "      <td>0.500271</td>\n",
       "      <td>0.495386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       ChestPainType_ASY  ChestPainType_ATA  ChestPainType_NAP  \\\n",
       "count         918.000000         918.000000         918.000000   \n",
       "mean            0.540305           0.188453           0.221133   \n",
       "std             0.498645           0.391287           0.415236   \n",
       "min             0.000000           0.000000           0.000000   \n",
       "25%             0.000000           0.000000           0.000000   \n",
       "50%             1.000000           0.000000           0.000000   \n",
       "75%             1.000000           0.000000           0.000000   \n",
       "max             1.000000           1.000000           1.000000   \n",
       "\n",
       "       ChestPainType_TA  RestingECG_LVH  RestingECG_Normal  RestingECG_ST  \\\n",
       "count        918.000000      918.000000         918.000000     918.000000   \n",
       "mean           0.050109        0.204793           0.601307       0.193900   \n",
       "std            0.218289        0.403770           0.489896       0.395567   \n",
       "min            0.000000        0.000000           0.000000       0.000000   \n",
       "25%            0.000000        0.000000           0.000000       0.000000   \n",
       "50%            0.000000        0.000000           1.000000       0.000000   \n",
       "75%            0.000000        0.000000           1.000000       0.000000   \n",
       "max            1.000000        1.000000           1.000000       1.000000   \n",
       "\n",
       "       ST_Slope_Down  ST_Slope_Flat  ST_Slope_Up  \n",
       "count     918.000000     918.000000   918.000000  \n",
       "mean        0.068627       0.501089     0.430283  \n",
       "std         0.252957       0.500271     0.495386  \n",
       "min         0.000000       0.000000     0.000000  \n",
       "25%         0.000000       0.000000     0.000000  \n",
       "50%         0.000000       1.000000     0.000000  \n",
       "75%         0.000000       1.000000     1.000000  \n",
       "max         1.000000       1.000000     1.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Три колонки преобразуем с помощью cols_to_dummies\n",
    "cols_to_dummies = ['ChestPainType', 'RestingECG', 'ST_Slope']\n",
    "data2 = pd.get_dummies(data[cols_to_dummies], columns=cols_to_dummies).copy()\n",
    "data2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "14cc4e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Две колонки с бинарными категориями преобразуем с помощью LabelEncoder\n",
    "from sklearn import preprocessing\n",
    "le_Sex = preprocessing.LabelEncoder()\n",
    "le_Sex.fit(data.Sex.unique())\n",
    "data_Sex_int = le_Sex.transform(data.Sex)\n",
    "# смотрим первые сто элементов\n",
    "data_Sex_int[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce306e91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вторая колонка\n",
    "le_ExerciseAngina = preprocessing.LabelEncoder()\n",
    "le_ExerciseAngina.fit(data.ExerciseAngina.unique())\n",
    "data_ExerciseAngina_int = le_ExerciseAngina.transform(data.ExerciseAngina)\n",
    "# смотрим первые сто элементов\n",
    "data_ExerciseAngina_int[0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d19996b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Целевая колонка (первые 5 строк):\n",
      "0    0\n",
      "1    1\n",
      "2    0\n",
      "3    1\n",
      "4    0\n",
      "Name: HeartDisease, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RestingBP</th>\n",
       "      <th>Cholesterol</th>\n",
       "      <th>FastingBS</th>\n",
       "      <th>MaxHR</th>\n",
       "      <th>Oldpeak</th>\n",
       "      <th>ChestPainType_ASY</th>\n",
       "      <th>ChestPainType_ATA</th>\n",
       "      <th>ChestPainType_NAP</th>\n",
       "      <th>ChestPainType_TA</th>\n",
       "      <th>RestingECG_LVH</th>\n",
       "      <th>RestingECG_Normal</th>\n",
       "      <th>RestingECG_ST</th>\n",
       "      <th>ST_Slope_Down</th>\n",
       "      <th>ST_Slope_Flat</th>\n",
       "      <th>ST_Slope_Up</th>\n",
       "      <th>Sex2</th>\n",
       "      <th>ExerciseAngina2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>140</td>\n",
       "      <td>289</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>49</td>\n",
       "      <td>160</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>156</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>37</td>\n",
       "      <td>130</td>\n",
       "      <td>283</td>\n",
       "      <td>0</td>\n",
       "      <td>98</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48</td>\n",
       "      <td>138</td>\n",
       "      <td>214</td>\n",
       "      <td>0</td>\n",
       "      <td>108</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>54</td>\n",
       "      <td>150</td>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>122</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  RestingBP  Cholesterol  FastingBS  MaxHR  Oldpeak  ChestPainType_ASY  \\\n",
       "0   40        140          289          0    172      0.0                  0   \n",
       "1   49        160          180          0    156      1.0                  0   \n",
       "2   37        130          283          0     98      0.0                  0   \n",
       "3   48        138          214          0    108      1.5                  1   \n",
       "4   54        150          195          0    122      0.0                  0   \n",
       "\n",
       "   ChestPainType_ATA  ChestPainType_NAP  ChestPainType_TA  RestingECG_LVH  \\\n",
       "0                  1                  0                 0               0   \n",
       "1                  0                  1                 0               0   \n",
       "2                  1                  0                 0               0   \n",
       "3                  0                  0                 0               0   \n",
       "4                  0                  1                 0               0   \n",
       "\n",
       "   RestingECG_Normal  RestingECG_ST  ST_Slope_Down  ST_Slope_Flat  \\\n",
       "0                  1              0              0              0   \n",
       "1                  1              0              0              1   \n",
       "2                  0              1              0              0   \n",
       "3                  1              0              0              1   \n",
       "4                  1              0              0              0   \n",
       "\n",
       "   ST_Slope_Up  Sex2  ExerciseAngina2  \n",
       "0            1     1                0  \n",
       "1            0     0                0  \n",
       "2            1     1                0  \n",
       "3            0     0                1  \n",
       "4            1     1                0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Соберем датасет признаков и выделим серию с целевой переменной\n",
    "X = pd.concat([data[['Age', 'RestingBP', 'Cholesterol', 'FastingBS', 'MaxHR', 'Oldpeak']], \n",
    "               data2, \n",
    "               pd.DataFrame({'Sex2': data_Sex_int}), \n",
    "               pd.DataFrame({'ExerciseAngina2': data_ExerciseAngina_int})], axis=1)\n",
    "y = data['HeartDisease'].copy()\n",
    "print(f'Целевая колонка (первые 5 строк):\\n{y[0:5]}')\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76cde53b",
   "metadata": {},
   "source": [
    "### 3. Разделите выборку на обучающее и тестовое подмножество. 80% данных оставить на обучающее множество, 20% на тестовое."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20f981db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(918, 18)\n",
      "(734, 18)\n"
     ]
    }
   ],
   "source": [
    "# Грузим модуль\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Разделяем:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=21) \n",
    "# смотрим, как прошло разбиение\n",
    "print(X.shape)\n",
    "print(X_train.shape)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b3fb19b",
   "metadata": {},
   "source": [
    "### 4. Обучите модель логистической регрессии с параметрами по умолчанию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "467dafb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Вначале - логистическая регрессия\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Создаем с параметрами по умолчанию \n",
    "data_logistic_regr = LogisticRegression(random_state=42)\n",
    "\n",
    "data_logistic_regr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8175240c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "MMScaler = MinMaxScaler()\n",
    "X_train_scale = MMScaler.fit_transform(X_train)\n",
    "#print(X_train_scale)\n",
    "\n",
    "# Создаем с параметрами по умолчанию \n",
    "data_logistic_regr_scale = LogisticRegression(random_state=42)\n",
    "\n",
    "data_logistic_regr_scale.fit(X_train_scale, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92840118",
   "metadata": {},
   "source": [
    "### 5. Подсчитайте основные метрики модели. Используйте следующие метрики и функцию:  \n",
    "<code>cross_validate(…, cv=10, scoring=[‘accuracy’,‘recall’,‘precision’,‘f1’])</code>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7185a140",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.14699173, 0.07499599, 0.04199791, 0.06499553, 0.04299712,\n",
       "        0.06099677, 0.03699732, 0.05499482, 0.04399633, 0.04499674]),\n",
       " 'score_time': array([0.00699854, 0.00699925, 0.00799894, 0.01299977, 0.00699925,\n",
       "        0.01300073, 0.00800061, 0.00699997, 0.00799918, 0.0179987 ]),\n",
       " 'test_accuracy': array([0.82608696, 0.93478261, 0.85869565, 0.93478261, 0.88043478,\n",
       "        0.83695652, 0.88043478, 0.82608696, 0.72527473, 0.76923077]),\n",
       " 'test_recall': array([0.76470588, 0.92156863, 0.82352941, 0.96078431, 0.98039216,\n",
       "        0.96078431, 0.98039216, 0.82352941, 0.78      , 0.72      ]),\n",
       " 'test_precision': array([0.90697674, 0.95918367, 0.91304348, 0.9245283 , 0.83333333,\n",
       "        0.79032258, 0.83333333, 0.85714286, 0.73584906, 0.8372093 ]),\n",
       " 'test_f1': array([0.82978723, 0.94      , 0.86597938, 0.94230769, 0.9009009 ,\n",
       "        0.86725664, 0.9009009 , 0.84      , 0.75728155, 0.77419355])}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "X_scale = MinMaxScaler().fit_transform(X)\n",
    "scores = cross_validate(data_logistic_regr_scale, X_scale, y, cv=10, scoring=['accuracy', 'recall', 'precision', 'f1'])\n",
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f64be3e",
   "metadata": {},
   "source": [
    "### 6. Оптимизируйте 3-4 параметра модели:  \n",
    "a) Используйте GridSearchCV.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d999532",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d9f9701f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры, вариации которых я пытался смотреть\n",
    "param_grid = {\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter': [10, 20, 50, 70, 100, 200],\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "    'c': [0.5, 0.75, 1, 1.5, 3]\n",
    "}\n",
    "\n",
    "# Здесь я несколько раз переопределял различные комбинации этих параметров, в результате чего смог увидеть,\n",
    "# что параметр C никак не влиял на результат, penalty = none было хорошим выбором, возможно потому, что данные нормализованы\n",
    "# max_iter =20 оказывается достаточным, solver=saga\n",
    "param_grid = {\n",
    "    'penalty': ['l2', 'none'],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter': [10, 20, 50, 70, 100, 200],\n",
    "    'C': [0.5, 0.75, 1, 1.5, 3]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "c1fea4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем grid\n",
    "grid = GridSearchCV(LogisticRegression(random_state=42), param_grid, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "02b75f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=LogisticRegression(random_state=42),\n",
       "             param_grid={'C': [0.5, 0.75, 1, 1.5, 3],\n",
       "                         'max_iter': [10, 20, 50, 70, 100, 200],\n",
       "                         'penalty': ['l2', 'none'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "grid.fit(X_train_scale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "97f50af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_score\n",
      " [0.85816364 0.86088486 0.86223621 0.85814513 0.85953351 0.86358756\n",
      " 0.85407257        nan 0.86084783 0.86088486 0.85816364 0.85816364\n",
      " 0.86223621 0.85816364 0.85953351 0.86358756 0.86358756        nan\n",
      " 0.86088486 0.86223621 0.85816364 0.85816364 0.86223621 0.85816364\n",
      " 0.85816364 0.86358756 0.86358756        nan 0.86358756 0.86358756\n",
      " 0.85816364 0.85816364 0.86223621 0.85816364 0.85816364 0.86358756\n",
      " 0.86358756        nan 0.86358756 0.86358756 0.85816364 0.85816364\n",
      " 0.86223621 0.85816364 0.85816364 0.86358756 0.86358756        nan\n",
      " 0.86358756 0.86358756 0.85816364 0.85816364 0.86223621 0.85816364\n",
      " 0.85816364 0.86358756 0.86358756        nan 0.86358756 0.86358756\n",
      " 0.86223621 0.86225472 0.86223621 0.85951499 0.86360607 0.86358756\n",
      " 0.85407257        nan 0.86084783 0.86088486 0.86223621 0.86223621\n",
      " 0.86223621 0.86223621 0.86223621 0.86358756 0.86358756        nan\n",
      " 0.86088486 0.86223621 0.86223621 0.86223621 0.86223621 0.86223621\n",
      " 0.86223621 0.86358756 0.86358756        nan 0.86358756 0.86358756\n",
      " 0.86223621 0.86223621 0.86223621 0.86223621 0.86223621 0.86358756\n",
      " 0.86358756        nan 0.86358756 0.86358756 0.86223621 0.86223621\n",
      " 0.86223621 0.86223621 0.86223621 0.86358756 0.86358756        nan\n",
      " 0.86358756 0.86358756 0.86223621 0.86223621 0.86223621 0.86223621\n",
      " 0.86223621 0.86358756 0.86358756        nan 0.86358756 0.86358756\n",
      " 0.86223621 0.85816364 0.86358756 0.86088486 0.86495742 0.86358756\n",
      " 0.85407257        nan 0.86084783 0.86088486 0.86223621 0.86088486\n",
      " 0.86358756 0.86223621 0.86495742 0.86358756 0.86358756        nan\n",
      " 0.86088486 0.86223621 0.86223621 0.86223621 0.86358756 0.86223621\n",
      " 0.86223621 0.86358756 0.86358756        nan 0.86358756 0.86358756\n",
      " 0.86223621 0.86223621 0.86358756 0.86223621 0.86223621 0.86358756\n",
      " 0.86358756        nan 0.86358756 0.86358756 0.86223621 0.86223621\n",
      " 0.86358756 0.86223621 0.86223621 0.86358756 0.86358756        nan\n",
      " 0.86358756 0.86358756 0.86223621 0.86223621 0.86358756 0.86223621\n",
      " 0.86223621 0.86358756 0.86358756        nan 0.86358756 0.86358756\n",
      " 0.86086635 0.85816364 0.86088486 0.85679378 0.86497593 0.86358756\n",
      " 0.85407257        nan 0.86084783 0.86088486 0.86086635 0.86223621\n",
      " 0.86088486 0.86223621 0.86223621 0.86358756 0.86358756        nan\n",
      " 0.86088486 0.86223621 0.86086635 0.86086635 0.86088486 0.86086635\n",
      " 0.86086635 0.86358756 0.86358756        nan 0.86358756 0.86358756\n",
      " 0.86086635 0.86086635 0.86088486 0.86086635 0.86086635 0.86358756\n",
      " 0.86358756        nan 0.86358756 0.86358756 0.86086635 0.86086635\n",
      " 0.86088486 0.86086635 0.86086635 0.86358756 0.86358756        nan\n",
      " 0.86358756 0.86358756 0.86086635 0.86086635 0.86088486 0.86086635\n",
      " 0.86086635 0.86358756 0.86358756        nan 0.86358756 0.86358756\n",
      " 0.86086635 0.85407257 0.85951499 0.8622177  0.85814513 0.86358756\n",
      " 0.85407257        nan 0.86084783 0.86088486 0.86086635 0.85951499\n",
      " 0.85951499 0.85951499 0.85951499 0.86358756 0.86358756        nan\n",
      " 0.86088486 0.86223621 0.86086635 0.86086635 0.85951499 0.86086635\n",
      " 0.86086635 0.86358756 0.86358756        nan 0.86358756 0.86358756\n",
      " 0.86086635 0.86086635 0.85951499 0.86086635 0.86086635 0.86358756\n",
      " 0.86358756        nan 0.86358756 0.86358756 0.86086635 0.86086635\n",
      " 0.85951499 0.86086635 0.86086635 0.86358756 0.86358756        nan\n",
      " 0.86358756 0.86358756 0.86086635 0.86086635 0.85951499 0.86086635\n",
      " 0.86086635 0.86358756 0.86358756        nan 0.86358756 0.86358756]\n",
      "\n",
      "rank_test_score\n",
      " [242 168 107 263 228  11 265 288 223 168 242 242 107 242 228  11  11 293\n",
      " 180 162 242 242 107 242 242  11  11 285  11  11 242 242 107 242 242  11\n",
      "  11 300  11  11 242 242 107 242 242  11  11 272  11  11 242 242 107 242\n",
      " 242  11  11 297  11  11 107 106 107 239   4  11 265 289 223 168 107 107\n",
      " 107 107 107  11  11 277 180 162 107 107 107 107 107  11  11 296  11  11\n",
      " 107 107 107 107 107  11  11 278  11  11 107 107 107 107 107  11  11 276\n",
      "  11  11 107 107 107 107 107  11  11 286  11  11 107 240   5 180   2  11\n",
      " 265 291 223 168 107 180   5 107   2  11  11 281 180 162 107 107   5 107\n",
      " 107  11  11 295  11  11 107 107   5 107 107  11  11 284  11  11 107 107\n",
      "   5 107 107  11  11 275  11  11 107 107   5 107 107  11  11 279  11  11\n",
      " 187 240 168 264   1  11 265 280 223 168 187 107 168 107 107  11  11 283\n",
      " 180 162 187 187 168 187 187  11  11 273  11  11 187 187 168 187 187  11\n",
      "  11 299  11  11 187 187 168 187 187  11  11 287  11  11 187 187 168 187\n",
      " 187  11  11 292  11  11 187 265 230 167 262  11 265 294 223 168 187 230\n",
      " 230 230 230  11  11 271 180 162 187 187 230 187 187  11  11 298  11  11\n",
      " 187 187 230 187 187  11  11 290  11  11 187 187 230 187 187  11  11 274\n",
      "  11  11 187 187 230 187 187  11  11 282  11  11]\n"
     ]
    }
   ],
   "source": [
    "#for k in grid.cv_results_:\n",
    "#    print(k, \":\", grid.cv_results_[k])\n",
    "\n",
    "print('mean_test_score\\n', grid.cv_results_['mean_test_score'])\n",
    "print('\\nrank_test_score\\n', grid.cv_results_['rank_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "6eed3add",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8649759348389485\n",
      "LogisticRegression(C=1.5, max_iter=10, random_state=42, solver='saga')\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "aadf62c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.01399946, 0.01599813, 0.04899764, 0.02399898, 0.05299664,\n",
       "        0.01899886, 0.0179975 , 0.02099872, 0.01699877, 0.01799726]),\n",
       " 'score_time': array([0.03899789, 0.01100159, 0.0069983 , 0.0179987 , 0.01699877,\n",
       "        0.01099944, 0.01200008, 0.0129993 , 0.00700068, 0.00799942]),\n",
       " 'test_accuracy': array([0.82608696, 0.92391304, 0.85869565, 0.95652174, 0.86956522,\n",
       "        0.84782609, 0.88043478, 0.82608696, 0.72527473, 0.79120879]),\n",
       " 'test_recall': array([0.76470588, 0.90196078, 0.82352941, 0.96078431, 0.98039216,\n",
       "        1.        , 0.98039216, 0.80392157, 0.76      , 0.72      ]),\n",
       " 'test_precision': array([0.90697674, 0.95833333, 0.91304348, 0.96078431, 0.81967213,\n",
       "        0.78461538, 0.83333333, 0.87234043, 0.74509804, 0.87804878]),\n",
       " 'test_f1': array([0.82978723, 0.92929293, 0.86597938, 0.96078431, 0.89285714,\n",
       "        0.87931034, 0.9009009 , 0.83673469, 0.75247525, 0.79120879])}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Задаем параметры, которые кажутся оптимальными после использования grid\n",
    "# Хотя код выше предложил в качестве оптимума max_iter = 10, ряд моих экспериментов показал, что 20 - лучше.\n",
    "data_logistic_regr_scale_grid = LogisticRegression(random_state=42, C=1.5, penalty='none', solver='saga', max_iter=20)\n",
    "data_logistic_regr_scale_grid.fit(X_train_scale, y_train)\n",
    "\n",
    "scores_after_grid = cross_validate(data_logistic_regr_scale_grid, X_scale, y, cv=10, scoring=['accuracy', 'recall', 'precision', 'f1'])\n",
    "scores_after_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "68d31dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика accuracy из умолчального эксперимента: 0.8472766364070713\n",
      "Метрика accuracy из эксперимента c grid: 0.8505613951266126\n"
     ]
    }
   ],
   "source": [
    "# Результаты оказались чуть-чуть лучше, чем с параметрами по умолчанию.\n",
    "print(f'Метрика accuracy из умолчального эксперимента: {scores[\"test_accuracy\"].mean()}')\n",
    "print(f'Метрика accuracy из эксперимента c grid: {scores_after_grid[\"test_accuracy\"].mean()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb101f0",
   "metadata": {},
   "source": [
    "### 6. Оптимизируйте 3-4 параметра модели:    \n",
    "b) Используйте RandomizedSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4bf794e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e8f3fe00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Повторяю и здесь свои эксперименты, которые проводил с Grid,\n",
    "# что параметр C никак не влиял на результат, penalty = none было хорошим выбором, возможно потому, что данные нормализованы\n",
    "# max_iter =20 оказывается достаточным, solver=saga\n",
    "param_rand_srch = {\n",
    "    'penalty': ['l2', 'none'],\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "    'max_iter': [10, 20, 50, 70, 100, 200],\n",
    "    'C': [0.5, 0.75, 1, 1.5, 3]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "be461802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# инициализируем grid\n",
    "rand_srch = RandomizedSearchCV(LogisticRegression(random_state=42), param_rand_srch, cv=10, scoring='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "55fff495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, estimator=LogisticRegression(random_state=42),\n",
       "                   param_distributions={'C': [0.5, 0.75, 1, 1.5, 3],\n",
       "                                        'max_iter': [10, 20, 50, 70, 100, 200],\n",
       "                                        'penalty': ['l2', 'none'],\n",
       "                                        'solver': ['newton-cg', 'lbfgs',\n",
       "                                                   'liblinear', 'sag',\n",
       "                                                   'saga']},\n",
       "                   scoring='accuracy')"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "rand_srch.fit(X_train_scale, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f18f54a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_test_score\n",
      " [0.86360607 0.85953351 0.86358756 0.86223621 0.86223621 0.86358756\n",
      " 0.86358756 0.86223621 0.86358756 0.86223621]\n",
      "\n",
      "rank_test_score\n",
      " [ 1 10  3  6  6  2  3  6  3  6]\n"
     ]
    }
   ],
   "source": [
    "print('mean_test_score\\n', rand_srch.cv_results_['mean_test_score'])\n",
    "print('\\nrank_test_score\\n', rand_srch.cv_results_['rank_test_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a9ee4ada",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.86360607182525\n",
      "LogisticRegression(C=0.75, max_iter=10, random_state=42, solver='saga')\n"
     ]
    }
   ],
   "source": [
    "print(rand_srch.best_score_)\n",
    "print(rand_srch.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "351df41a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fit_time': array([0.00899839, 0.05299616, 0.01199865, 0.02599859, 0.0129993 ,\n",
       "        0.02399778, 0.01399803, 0.01499915, 0.01299906, 0.01599836]),\n",
       " 'score_time': array([0.00699973, 0.01099992, 0.00700068, 0.00799847, 0.01099944,\n",
       "        0.01400042, 0.01099968, 0.00700045, 0.00699925, 0.01199937]),\n",
       " 'test_accuracy': array([0.82608696, 0.93478261, 0.85869565, 0.94565217, 0.86956522,\n",
       "        0.83695652, 0.88043478, 0.82608696, 0.72527473, 0.76923077]),\n",
       " 'test_recall': array([0.76470588, 0.92156863, 0.82352941, 0.96078431, 0.98039216,\n",
       "        0.98039216, 0.98039216, 0.82352941, 0.76      , 0.7       ]),\n",
       " 'test_precision': array([0.90697674, 0.95918367, 0.91304348, 0.94230769, 0.81967213,\n",
       "        0.78125   , 0.83333333, 0.85714286, 0.74509804, 0.85365854]),\n",
       " 'test_f1': array([0.82978723, 0.94      , 0.86597938, 0.95145631, 0.89285714,\n",
       "        0.86956522, 0.9009009 , 0.84      , 0.75247525, 0.76923077])}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Задаем параметры, которые кажутся оптимальными после использования RandomSearch\n",
    "data_logistic_regr_scale_rand_srch = LogisticRegression(random_state=42, C=0.75, penalty='none', solver='saga', max_iter=10)\n",
    "data_logistic_regr_scale_rand_srch.fit(X_train_scale, y_train)\n",
    "\n",
    "scores_after_rand_srch = cross_validate(data_logistic_regr_scale_rand_srch, X_scale, y, cv=10, scoring=['accuracy', 'recall', 'precision', 'f1'])\n",
    "scores_after_rand_srch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03a8bc3d",
   "metadata": {},
   "source": [
    "### 7. Сформулируйте выводы по проделанной работе:  \n",
    "a) Сравните метрики построенных моделей.  \n",
    "b) *Сравните с полученными результатами в домашнем задании по теме «Ансамблирование»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "8aea3e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Метрика accuracy из умолчального эксперимента: 0.8472766364070713\n",
      "Метрика accuracy из эксперимента c grid: 0.8505613951266126\n",
      "Метрика accuracy из эксперимента c random search: 0.8472766364070712\n"
     ]
    }
   ],
   "source": [
    "# Выводим рядом все три результата\n",
    "print(f'Метрика accuracy из умолчального эксперимента: {scores[\"test_accuracy\"].mean()}')\n",
    "print(f'Метрика accuracy из эксперимента c grid: {scores_after_grid[\"test_accuracy\"].mean()}')\n",
    "print(f'Метрика accuracy из эксперимента c random search: {scores_after_rand_srch[\"test_accuracy\"].mean()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2899703f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Фактически удалось чуть-чуть улучшить точность предсказания благодаря внимательному просмотру нескольких запусков\n",
    "\n",
    "# grid с разными комбинациями параметров и установка пойманного в ходе тех экспериментов значения вопреки рекомендации\n",
    "# Понимаю, что некоторые из использованных мною диапазонов значений - результат случайного выбора чисел. \n",
    "# По хорошему можно было бы добавить дополнительные числа для расширения диапазона экспериментов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6799a928",
   "metadata": {},
   "source": [
    "#### В работе по изучению ансамблирования были получены следующие результаты точности:\n",
    "- Точность 0.8152, модель DecisionTreeClassifier\n",
    "- Точность 0.8859, модель RandomForestClassifier\n",
    "- Точность 0.8533, модель DecisionTreeClassifier, n_estimators=10\n",
    "- Точность 0.8533, модель DecisionTreeClassifier, n_estimators=20\n",
    "- Точность 0.8641, модель DecisionTreeClassifier, n_estimators=30\n",
    "- Точность 0.8587, модель StackingClassifier with LogisticRegression, n_estimators=10\n",
    "- Точность 0.7989, модель StackingClassifier with DecisionTreeClassifier, n_estimators=10\n",
    "- Точность 0.8261, модель StackingClassifier with RandomForestClassifier, n_estimators=10\n",
    "\n",
    "При этом в той работе LogisticRegression не использовалось, и видно, что RandomForestClassifier при использовании методов ансамблирования явно оказался более убедительным, чем Логистическая регрессия в текущем задании."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
